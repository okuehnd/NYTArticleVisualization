# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O6S0ngpC-OJ_tjt-57p1FP5e9Hh8HC1P
"""

import kagglehub
import pandas as pd

# Commented out IPython magic to ensure Python compatibility.
# %pip install kaggle

from google.colab import files
files.upload()  # Upload kaggle.json when prompted

# Move kaggle.json to the .kaggle directory
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d aryansingh0909/nyt-articles-21m-2000-present

import zipfile
path = "/content/NYT DATA"
with zipfile.ZipFile('nyt-articles-21m-2000-present.zip', 'r') as zip_ref:
    zip_ref.extractall(path)  # Adjust the path if necessary

import os
os.listdir(path)

df = pd.read_csv(path+"/nyt-metadata.csv")

articles_only = df[df['document_type'] == 'article']
articles_only = articles_only.dropna(subset=['section_name'])
print(articles_only['section_name'].unique())

"""I think we should get rid of Obituaries because there is no really good/bad sentiment. Member center because it just seems like maintenance stuff. Archives because they are from a bunch of different print sections so for our purpose it does not give value (cant easily separate topics).Corrections because it is just correcting a previous article. May give duplicated points for articles. Crosswords & games because while some are good articles.. too many are about the actual crosswords and games in the NYT and have nonsense abstracts.'xword' is crossword answers that was only used 3 times. I want to get rid of 'Today's Paper but am having issues. Reader Center is the NYT responding to reader comments basically. I think thiis could double sentiments for the same article again. Homepage is short and useless. 'readersopinions' is summaries from reader forums-- again I think it would repeat the content of some articles. 'Admin' seems to be a mix between admin stuff for corrections and cooking stuff?? I think we'll have to review this one more maybe. For now, removing. 'Week in Review' will 1. have repeated sentiments from articles that week, 2. Will have a mix of sentiments from all the articles that week. 'Critic's Choice' is basically like little riddles-- OUT.

"""

curr_sect = 'Podcasts'
removeList = ['Obituaries', 'membercenter','Archives','Corrections','Crosswords & Games','none','xword','Reader Center','Homepage','readersopinions','Admin','Week in Review','Critic\'s Choice','Topics']

rowWithSelection = articles_only[articles_only['section_name'] == curr_sect]
rowWithSelection.head(5)
# print(rowWithSelection.head(1)['abstract'].values[0])
print(rowWithSelection.iloc[20]['abstract'])
# print(rowWithSelection.iloc[5]['web_url'])

from transformers import pipeline

val = 8
# Load a sentiment-analysis pipeline
sentiment_pipeline = pipeline("sentiment-analysis")

# Text to analyze
text = df['snippet'][val]
print(text)

# Run sentiment analysis
result = sentiment_pipeline(text)[0]

print(result)

#cleaning
print("Starting Shape: ",df.shape)
df = df.dropna(subset = ['abstract'])
print("Shape after dropping NaN for abstract:",df.shape) #One of these must have a value to do a sentiment analysis I think we prioritize abstract then snippet then lead
df = df.dropna(subset = ['keywords'])
print("Shape after dropping for keywords:",df.shape) #need key words to do keyword analysis
df = df.dropna(subset = ['section_name'])  #no awesome mapping for print section to section name. Only keeping section name
print("Shape after dropping for print section or section name:",df.shape) #If we want to compare sections, then at least one of these must have a value
df = df.dropna(subset = ['web_url','headline'])
print("Shape after dropping for web_url and headline:",df.shape) #want to title and link articles if user wants to read the articles from certain keywords
df = df = df[df['document_type'] == 'article']
print("Shape after only choosing articles:",df.shape) #we only want articles right? Not audio or multimedia?
df = df.dropna(subset = ['pub_date'])
print("Shape after dropping for pub date:", df.shape) #need a date to plot on a timeline
df = df.dropna(subset=['_id'])
print("Shape after dropping for id:",df.shape)
df = df[~((df['section_name'] == 'The Learning Network') & (df['abstract'].str.contains('.menu', na=False)))]
print("Shape after cleaning Learning Network",df.shape)
df = df[~df['section_name'].isin(removeList)]
print("Shape after removing removeList from column (section_name):",df.shape)

articles = df #work with smaller set to make sure the analysis works before we use for
sentiment_pipeline = pipeline("sentiment-analysis") #create sentiment pipeline

#Negative : -1 , POSITIVE: 1
#create new column in df with pos/neg and another with score
articles['sentiment'] = 0
articles['sentiment_score'] = 0.0
error_indices = []

for index,row in articles.iterrows():
  try:
    sentiment = sentiment_pipeline(row['abstract'])[0]
    articles.at[index,'sentiment'] = 1 if sentiment['label'] == 'POSITIVE' else -1
    articles.at[index,'sentiment_score'] = sentiment['score']
  except Exception as e:
    print(f"An unexpected error occurred: {e}")
    error_indices.extend(articles.index[articles['_id'].str.contains(row['_id'])].tolist())

print("Error Indices:\n",error_indices)